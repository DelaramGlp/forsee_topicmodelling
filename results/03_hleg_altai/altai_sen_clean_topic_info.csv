Topic,Count,Name,Representation,Representative_Docs
-1,94,-1_rights_explainability_accountability_information,"['rights', 'explainability', 'accountability', 'information', 'administrators', 'security', 'processes', 'transparency', 'technical', 'oversight']","['have you put in place processes to address and rectify for potential infringement on freedom of expression and information freedom of assembly and association in the ai system', 'in that period this assessment list for trustworthy ai altai also benefited from piloting phase second half of through that piloting phase the ai hleg received valuable feedback through fifty interviews with selected companies input through an open work stream on the ai to provide best practices and via two publicly accessible questionnaires for technical and this assessment list altai is firmly grounded in the protection of people fundamental rights which is the term used in the european union to refer to human rights enshrined in the eu the charter of fundamental rights the charter and international human rights please consult the text box below on fundamental rights to familiarise yourself with the concept and with the content of fundamental rights impact assessment', 'have you put in place processes to test and monitor for potential infringement on freedom of expression and information freedom of assembly and association during the development deployment and use phases of the ai system']"
0,73,0_systems_human_environment_autonomy,"['systems', 'human', 'environment', 'autonomy', 'knowledge', 'oversight', 'behaviour', 'risk', 'affect', 'societal']","['in this section ai systems are assessed in terms of their respect for human agency and autonomy as well as human oversight', 'human agency and autonomy this subsection deals with the effect ai systems can have on human behaviour in the broadest sense', 'it deals with the effect of ai systems that are aimed at guiding influencing or supporting humans in decision making processes for example algorithmic decision support systems risk systems recommender systems predictive policing financial risk analysis etc']"
1,48,1_bias_fairness_subjects_discrimination,"['bias', 'fairness', 'subjects', 'discrimination', 'biases', 'diversity', 'harm', 'assess', 'communities', 'race']","['have you put in place processes to address and rectify for potential negative discrimination bias in the ai system', 'have you put in place processes to test and monitor for potential negative discrimination bias during the development deployment and use phases of the ai system', 'avoidance of unfair bias did you establish strategy or set of procedures to avoid creating or reinforcing unfair bias in the ai system both regarding the use of input data as well as for the algorithm design']"
2,42,2_trustworthy_altai_list_assessment,"['trustworthy', 'altai', 'list', 'assessment', 'ethics', 'guidelines', 'glossary', 'agency', 'accountability', 'intelligence']","['assessment list for trustworthy ai altai introduction in the expert group on artificial intelligence ai hleg set up by the european commission published the ethics guidelines for trustworthy artificial the third chapter of those guidelines contained an assessment list to help assess whether the ai system that is being developed deployed procured or used adheres to the seven requirements of trustworthy artificial intelligence ai as specified in our ethics guidelines for trustworthy ai', 'assessment list for trustworthy ai altai independent expert group on artificial intelligence set up by the european commission the assessment list for trustworthy artificial intelligence altai for self assessment assessment list for trustworthy ai altai table of contents introduction how to use this assessment list for trustworthy ai altai requirement human agency and oversight human agency and autonomy human oversight requirement technical robustness and safety resilience to attack and security general safety accuracy reliability plans and reproducibility requirement privacy and data governance privacy data governance requirement transparency traceability explainability communication requirement diversity and fairness avoidance of unfair bias accessibility and universal design stakeholder participation requirement societal and environmental environmental impact on work and skills impact on society at large or democracy requirement accountability auditability risk management glossary this document was written by the expert group on ai ai hleg', 'an online interactive version of this assessment list for trustworthy ai altai is how to use this assessment list for trustworthy ai altai this assessment list for trustworthy ai altai is best completed involving multidisciplinary team of people']"
3,41,3_privacy_governance_dpo_encryption,"['privacy', 'governance', 'dpo', 'encryption', 'pseudonymisation', 'integrity', 'gdpr', 'anonymisation', 'officer', 'assessment']","['see the section on privacy and data governance in this assessment list and available guidance from the european data protection', 'data protection impact assessment dpia evaluation of the effects that the processing of personal data might have on individuals to whom the data relates', 'glossary aggregation and anonymisation ai system data governance data protection impact assessment dpia data protection officer dpo encryption lifecycle pseudonymisation standards use case']"
4,37,4_accuracy_poisoning_attacks_ml,"['accuracy', 'poisoning', 'attacks', 'ml', 'training', 'adversarial', 'sensor', 'evasion', 'models', 'anomaly']","['data poisoning data poisoning occurs when an adversarial actor attacks an ai system and is able to inject bad data into the ai model training set thus making the ai system learn something that it should not learn', 'so model inversion turns the usual path from training data into model from one to one permitting the training data to be estimated from the model with varying degrees of accuracy', 'these cases are referred to as blackboxes and require this could take the form of standard automated quality assessment of data input quantifying missing values gaps in the data exploring breaks in the data supply detecting when data is insufficient for task detecting when the input data is erroneous incorrect inaccurate or mismatched in format']"
5,18,5_safety_failure_red_reliability,"['safety', 'failure', 'red', 'reliability', 'redundancy', 'vulnerabilities', 'faults', 'components', 'reproducibility', 'outages']","['to human or societal safety in case of risks or threats such as design or technical faults defects outages attacks misuse inappropriate or malicious use', 'general safety did you define risks risk metrics and risk levels of the ai system in each specific use case', 'fault tolerance fault tolerance is the property that enables system to continue operating properly in the event of the failure of or one or more faults within some of its components']"
6,18,6_standards_requirements_international_services,"['standards', 'requirements', 'international', 'services', 'organisation', 'industry', 'iso', 'methodological', 'standardisation', 'norms']","['it could be about making product managing process delivering service or supplying materials standards cover huge range of activities', 'standards standards are norms designed by industry governments that set product or services specifications', 'standards are released by international organizations such as iso international organisation for standardisation ieee the institute of electrical and electronics engineers standard association and nist national institute of standards and technology']"
7,16,7_design_accessibility_disabilities_universal,"['design', 'accessibility', 'disabilities', 'universal', 'technologies', 'inclusive', 'devices', 'usability', 'groups', 'keyboards']","['ai systems should not have approach and should consider universal design addressing the widest possible range of users following relevant accessibility this will enable equitable access and active participation of all people in existing and emerging human activities and with regard to assistive technologies', 'the design for all approach focuses on user involvement and experiences during the design and development process to achieve accessibility and usability', 'universal design terms such as design for all universal design accessible design design inclusive design and transgenerational design are often used interchangeably with the same meaning']"
8,14,8_traceability_lifecycle_workflow_logging,"['traceability', 'lifecycle', 'workflow', 'logging', 'training', 'maintenance', 'stages', 'deployment', 'versioning', 'journey']","['workflow of the model the workflow of an ai model shows the phases needed to build the model and their interdependencies', 'typical phases are data collection and preparation model development model training model accuracy evaluation hyperparameters tuning model usage model maintenance model versioning', 'lifecycle the lifecycle of an ai system includes several interdependent phases ranging from its design and development including such as requirement analysis data collection training testing integration installation deployment operation maintenance and disposal']"
9,13,9_document_charlotte_copyright_isbn,"['document', 'charlotte', 'copyright', 'isbn', 'drawing', 'echr', 'editorial', 'photos', 'formulation', 'convention']","['the members of the ai hleg named in this document have contributed to the formulation of the content throughout the running of their mandate', 'although commission staff facilitated the preparation thereof the views expressed in this document reflect the opinion of the ai hleg only and may not in any circumstances be regarded as reflecting an official position of the european commission', 'the following ai hleg members contributed to the revision of specific key requirements in alphabetical order human agency and oversight joanna goodey fredrik heintz technical robustness and safety yann bonnet raja chatila pierre lucas andrea renda george sharkov jaan tallinn cecile wendling privacy and data governance cecilia fanny hidvegi transparency mária bieliková ieva martinkenaite ursula pachl diversity and fairness klaus höckner francesca rossi societal and environmental mark coeckelbergh virginia dignum sabine theresia köszegi accountability robert kroplewski christoph peylo stefano quintarelli glossary nicolas petit francesca rossi the revisions were directly informed by the piloting of the assessment list conducted in the second half of']"
10,13,10_limitations_usable_interface_inform,"['limitations', 'usable', 'interface', 'inform', 'risk', 'capabilities', 'assistive', 'assess', 'criteria', 'disclaimers']","['did you provide appropriate training material and disclaimers to users on how to adequately use the ai system', 'did you organise risk training and if so does this also inform about the potential legal framework applicable to the ai system', 'did you provide appropriate training to those involved in such process and does this also cover the legal framework applicable to the ai system']"
11,11,11_participation_stakeholders_feedback_developers,"['participation', 'stakeholders', 'feedback', 'developers', 'development', 'stakeholder', 'capabilities', 'organisations', 'misunderstandings', 'prototypes']","['ai designers also work with development teams to better understand user needs and how to build technology that addresses those needs', 'it is beneficial to solicit regular feedback even after deployment and set up longer term mechanisms for stakeholder participation for example by ensuring workers information consultation and participation throughout the whole process of implementing ai systems at organisations', 'this depends on the organisation if developers are involved directly with user interactions through workshops etc they could be addressed by this question if they are not directly involved the organisation needs to make sure users understand the ai system and highlight any misunderstandings to the developing team']"
12,11,12_auditability_audit_audits_audited,"['auditability', 'audit', 'audits', 'audited', 'applications', 'traceability', 'entity', 'detect', 'assurance', 'auditors']","['audit an audit is an independent examination of some required properties of an entity be it company product or piece of software', 'auditability auditability refers to the ability of an ai system to undergo the assessment of the system algorithms data and design processes', 'traceability auditability and transparent communication on the ai system capabilities may be required provided that the ai system as whole respects fundamental rights']"
13,10,13_risks_process_management_topic,"['risks', 'process', 'management', 'topic', 'mitigating', 'counteract', 'addiction', 'intentions', 'communicating', 'manipulation']","['did you take measures to counteract risks', 'generate risks and to identify whether and what kind of active measures may need to be taken to avoid and minimise those risks', 'this topic is closely related to risk management identifying and mitigating risks in transparent way that can be explained to and audited by third parties']"
